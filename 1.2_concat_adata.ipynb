{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S13_L002_adata_keep.h5ad',\n",
       " 'S13_L003_adata_keep.h5ad',\n",
       " 'S13_L004_adata_keep.h5ad',\n",
       " 'S13_L005_adata_keep.h5ad',\n",
       " 'S13_L006_adata_keep.h5ad',\n",
       " 'S13_L007_adata_keep.h5ad',\n",
       " 'S13_L008_adata_keep.h5ad',\n",
       " 'S14_L002_adata_keep.h5ad',\n",
       " 'S14_L003_adata_keep.h5ad',\n",
       " 'S14_L004_adata_keep.h5ad',\n",
       " 'S14_L005_adata_keep.h5ad',\n",
       " 'S14_L006_adata_keep.h5ad',\n",
       " 'S14_L007_adata_keep.h5ad',\n",
       " 'S14_L008_adata_keep.h5ad',\n",
       " 'S15_L002_adata_keep.h5ad',\n",
       " 'S15_L003_adata_keep.h5ad',\n",
       " 'S15_L004_adata_keep.h5ad',\n",
       " 'S15_L005_adata_keep.h5ad',\n",
       " 'S15_L006_adata_keep.h5ad',\n",
       " 'S15_L007_adata_keep.h5ad',\n",
       " 'S15_L008_adata_keep.h5ad',\n",
       " 'S16_L002_adata_keep.h5ad',\n",
       " 'S16_L003_adata_keep.h5ad',\n",
       " 'S16_L004_adata_keep.h5ad',\n",
       " 'S16_L005_adata_keep.h5ad',\n",
       " 'S16_L006_adata_keep.h5ad',\n",
       " 'S16_L007_adata_keep.h5ad',\n",
       " 'S16_L008_adata_keep.h5ad',\n",
       " 'S17_L002_adata_keep.h5ad',\n",
       " 'S17_L003_adata_keep.h5ad',\n",
       " 'S17_L004_adata_keep.h5ad',\n",
       " 'S17_L005_adata_keep.h5ad',\n",
       " 'S17_L006_adata_keep.h5ad',\n",
       " 'S17_L007_adata_keep.h5ad',\n",
       " 'S17_L008_adata_keep.h5ad',\n",
       " 'S18_L002_adata_keep.h5ad',\n",
       " 'S18_L003_adata_keep.h5ad',\n",
       " 'S18_L004_adata_keep.h5ad',\n",
       " 'S18_L005_adata_keep.h5ad',\n",
       " 'S18_L006_adata_keep.h5ad',\n",
       " 'S18_L007_adata_keep.h5ad',\n",
       " 'S18_L008_adata_keep.h5ad',\n",
       " 'S1_L001_adata_keep.h5ad',\n",
       " 'S1_L002_adata_keep.h5ad',\n",
       " 'S1_L003_adata_keep.h5ad',\n",
       " 'S1_L004_adata_keep.h5ad',\n",
       " 'S1_L005_adata_keep.h5ad',\n",
       " 'S1_L006_adata_keep.h5ad',\n",
       " 'S1_L007_adata_keep.h5ad',\n",
       " 'S1_L008_adata_keep.h5ad',\n",
       " 'S2_L002_adata_keep.h5ad',\n",
       " 'S2_L003_adata_keep.h5ad',\n",
       " 'S2_L004_adata_keep.h5ad',\n",
       " 'S2_L005_adata_keep.h5ad',\n",
       " 'S2_L006_adata_keep.h5ad',\n",
       " 'S2_L007_adata_keep.h5ad',\n",
       " 'S2_L008_adata_keep.h5ad',\n",
       " 'S3_L002_adata_keep.h5ad',\n",
       " 'S3_L003_adata_keep.h5ad',\n",
       " 'S3_L004_adata_keep.h5ad',\n",
       " 'S3_L005_adata_keep.h5ad',\n",
       " 'S3_L006_adata_keep.h5ad',\n",
       " 'S3_L007_adata_keep.h5ad',\n",
       " 'S3_L008_adata_keep.h5ad',\n",
       " 'S4_L002_adata_keep.h5ad',\n",
       " 'S4_L003_adata_keep.h5ad',\n",
       " 'S4_L004_adata_keep.h5ad',\n",
       " 'S4_L005_adata_keep.h5ad',\n",
       " 'S4_L006_adata_keep.h5ad',\n",
       " 'S4_L007_adata_keep.h5ad',\n",
       " 'S4_L008_adata_keep.h5ad',\n",
       " 'S5_L002_adata_keep.h5ad',\n",
       " 'S5_L003_adata_keep.h5ad',\n",
       " 'S5_L004_adata_keep.h5ad',\n",
       " 'S5_L005_adata_keep.h5ad',\n",
       " 'S5_L006_adata_keep.h5ad',\n",
       " 'S5_L007_adata_keep.h5ad',\n",
       " 'S5_L008_adata_keep.h5ad',\n",
       " 'S6_L002_adata_keep.h5ad',\n",
       " 'S6_L003_adata_keep.h5ad',\n",
       " 'S6_L004_adata_keep.h5ad',\n",
       " 'S6_L005_adata_keep.h5ad',\n",
       " 'S6_L006_adata_keep.h5ad',\n",
       " 'S6_L007_adata_keep.h5ad',\n",
       " 'S6_L008_adata_keep.h5ad']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the downloaded output file names and combine file with same S\n",
    "adataNames = os.listdir('./adataObjsKeep/')\n",
    "adataList = []\n",
    "adataNames.sort()\n",
    "adataNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S13': [0, 1, 2, 3, 4, 5, 6],\n",
       " 'S14': [7, 8, 9, 10, 11, 12, 13],\n",
       " 'S15': [14, 15, 16, 17, 18, 19, 20],\n",
       " 'S16': [21, 22, 23, 24, 25, 26, 27],\n",
       " 'S17': [28, 29, 30, 31, 32, 33, 34],\n",
       " 'S18': [35, 36, 37, 38, 39, 40, 41],\n",
       " 'S1': [42, 43, 44, 45, 46, 47, 48, 49],\n",
       " 'S2': [50, 51, 52, 53, 54, 55, 56],\n",
       " 'S3': [57, 58, 59, 60, 61, 62, 63],\n",
       " 'S4': [64, 65, 66, 67, 68, 69, 70],\n",
       " 'S5': [71, 72, 73, 74, 75, 76, 77],\n",
       " 'S6': [78, 79, 80, 81, 82, 83, 84]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save same sample indices in a dictionary\n",
    "samples = []\n",
    "sampleDict = {}\n",
    "for i,an in enumerate(adataNames):\n",
    "    match = re.search('S[0-9]+',an).group()\n",
    "    samples.append(match)\n",
    "    if match in sampleDict:\n",
    "        sampleDict[match].append(i)\n",
    "    else:\n",
    "        sampleDict[match] = [i]\n",
    "sampleDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S13', 'S14', 'S15', 'S16', 'S17', 'S18', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sampleDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file S14\n",
      "[AnnData object with n_obs × n_vars = 14677 × 60623 \n",
      "    layers: 'spliced', 'unspliced', AnnData object with n_obs × n_vars = 10288 × 60623 \n",
      "    layers: 'spliced', 'unspliced', AnnData object with n_obs × n_vars = 15612 × 60623 \n",
      "    layers: 'spliced', 'unspliced', AnnData object with n_obs × n_vars = 10283 × 60623 \n",
      "    layers: 'spliced', 'unspliced', AnnData object with n_obs × n_vars = 15173 × 60623 \n",
      "    layers: 'spliced', 'unspliced', AnnData object with n_obs × n_vars = 15999 × 60623 \n",
      "    layers: 'spliced', 'unspliced', AnnData object with n_obs × n_vars = 16848 × 60623 \n",
      "    layers: 'spliced', 'unspliced']\n",
      "converting to array\n",
      "adding values\n",
      "done 0 of file no 1 of 7\n",
      "done 10000 of file no 1 of 7\n",
      "done 0 of file no 2 of 7\n",
      "done 10000 of file no 2 of 7\n",
      "done 0 of file no 3 of 7\n",
      "done 10000 of file no 3 of 7\n",
      "done 0 of file no 4 of 7\n",
      "done 10000 of file no 4 of 7\n",
      "done 0 of file no 5 of 7\n",
      "done 10000 of file no 5 of 7\n",
      "done 0 of file no 6 of 7\n",
      "done 10000 of file no 6 of 7\n",
      "done 0 of file no 7 of 7\n",
      "done 10000 of file no 7 of 7\n",
      "converting into sparse matrices\n",
      "joint adata is:\n",
      "AnnData object with n_obs × n_vars = 23215 × 60623 \n",
      "    layers: 'spliced', 'unspliced'\n",
      "writing file S14\n",
      "file S15\n",
      "[AnnData object with n_obs × n_vars = 15127 × 60623 \n",
      "    layers: 'spliced', 'unspliced', AnnData object with n_obs × n_vars = 10773 × 60623 \n",
      "    layers: 'spliced', 'unspliced', AnnData object with n_obs × n_vars = 16031 × 60623 \n",
      "    layers: 'spliced', 'unspliced', AnnData object with n_obs × n_vars = 10912 × 60623 \n",
      "    layers: 'spliced', 'unspliced', AnnData object with n_obs × n_vars = 15627 × 60623 \n",
      "    layers: 'spliced', 'unspliced', AnnData object with n_obs × n_vars = 16189 × 60623 \n",
      "    layers: 'spliced', 'unspliced', AnnData object with n_obs × n_vars = 15980 × 60623 \n",
      "    layers: 'spliced', 'unspliced']\n",
      "converting to array\n",
      "adding values\n",
      "done 0 of file no 1 of 7\n",
      "done 10000 of file no 1 of 7\n",
      "done 0 of file no 2 of 7\n",
      "done 10000 of file no 2 of 7\n",
      "done 0 of file no 3 of 7\n",
      "done 10000 of file no 3 of 7\n",
      "done 0 of file no 4 of 7\n",
      "done 10000 of file no 4 of 7\n",
      "done 0 of file no 5 of 7\n",
      "done 10000 of file no 5 of 7\n",
      "done 0 of file no 6 of 7\n",
      "done 10000 of file no 6 of 7\n",
      "done 0 of file no 7 of 7\n",
      "done 10000 of file no 7 of 7\n",
      "converting into sparse matrices\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The idea is to loop through each sample and then join them together\n",
    "for s in list(sampleDict.keys())[1:]:\n",
    "# for s in sampleDict.keys()\n",
    "    print('file ' + s)\n",
    "    adataList = []\n",
    "    indices = sampleDict[s]\n",
    "    for i in indices:\n",
    "        adataList.append(ad.read_h5ad('./adataObjsKeep/'+ adataNames[i]))\n",
    "    print(adataList)\n",
    "    checkSameVar = []\n",
    "    for i in range(1,len(adataList)):\n",
    "        checkSameVar.append(all(adataList[i].var.index == adataList[i-1].var.index))\n",
    "    check = all(checkSameVar)\n",
    "    assert check == True, \"The vars are not same in all adata\"\n",
    "    #convert each sparse matrix to array\n",
    "    print('converting to array')\n",
    "    XList = []\n",
    "    SList = []\n",
    "    UList = []\n",
    "    obs = []\n",
    "    var_names = list(adataList[0].var.index)\n",
    "    obsNames = []\n",
    "    for an in adataList:\n",
    "        XList.append(an.X.toarray())\n",
    "        SList.append(an.layers['spliced'].toarray())\n",
    "        UList.append(an.layers['unspliced'].toarray())\n",
    "        obsNames += list(an.obs.index.values)\n",
    "    cellBarcodes = set(obsNames)\n",
    "    rows = len(cellBarcodes)\n",
    "    cols = adataList[0].shape[1]\n",
    "    cellDict = dict(zip(cellBarcodes,range(rows)))\n",
    "    X = np.zeros((rows,cols))\n",
    "    S = np.zeros((rows,cols))\n",
    "    U = np.zeros((rows,cols))\n",
    "    print('adding values')\n",
    "    for i in range(len(adataList)):\n",
    "        for j in range(adataList[i].shape[0]):\n",
    "            if j % 10000 == 0:\n",
    "                print('done ' + str(j) + ' of file no ' + str(i+1) + ' of ' + str(len(adataList)))\n",
    "            idx = cellDict[adataList[i].obs.index[j]]\n",
    "            X[idx] = X[idx] + XList[i][j]\n",
    "            S[idx] = S[idx] + SList[i][j]\n",
    "            U[idx] = U[idx] + UList[i][j]\n",
    "    print('converting into sparse matrices')\n",
    "    X = scp.sparse.csr_matrix(X)\n",
    "    S = scp.sparse.csr_matrix(S)\n",
    "    U = scp.sparse.csr_matrix(U)\n",
    "    concatAdata = ad.AnnData(X,\n",
    "                  {'obs_names': cellBarcodes},\n",
    "                  {'var_names': var_names},\n",
    "                   layers={'spliced':S,\n",
    "                          'unspliced':U})\n",
    "    filename = './jointAdata/' + s + '.h5ad'\n",
    "    print('joint adata is:')\n",
    "    print(concatAdata)\n",
    "    print('writing file ' + s)\n",
    "    concatAdata.write(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<23216x60623 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 9208121 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adat = ad.read_h5ad('jointAdata/S13.h5ad')\n",
    "adat.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file S13\n",
      "[AnnData object with n_obs × n_vars = 15342 × 60623 \n",
      "    layers: 'spliced', 'unspliced', AnnData object with n_obs × n_vars = 10895 × 60623 \n",
      "    layers: 'spliced', 'unspliced', AnnData object with n_obs × n_vars = 16222 × 60623 \n",
      "    layers: 'spliced', 'unspliced', AnnData object with n_obs × n_vars = 10928 × 60623 \n",
      "    layers: 'spliced', 'unspliced', AnnData object with n_obs × n_vars = 15800 × 60623 \n",
      "    layers: 'spliced', 'unspliced', AnnData object with n_obs × n_vars = 16479 × 60623 \n",
      "    layers: 'spliced', 'unspliced', AnnData object with n_obs × n_vars = 17295 × 60623 \n",
      "    layers: 'spliced', 'unspliced']\n"
     ]
    }
   ],
   "source": [
    "for s in list(sampleDict.keys())[:1]:\n",
    "# for s in sampleDict.keys()\n",
    "    print('file ' + s)\n",
    "    adataList = []\n",
    "    indices = sampleDict[s]\n",
    "    for i in indices:\n",
    "        adataList.append(ad.read_h5ad('./adataObjsKeep/'+adataNames[i]))\n",
    "    print(adataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convering to array\n",
      "adding values\n",
      "done 0of file no 1 of 7\n",
      "done 1000of file no 1 of 7\n",
      "done 2000of file no 1 of 7\n",
      "done 3000of file no 1 of 7\n",
      "done 4000of file no 1 of 7\n",
      "done 5000of file no 1 of 7\n",
      "done 6000of file no 1 of 7\n",
      "done 7000of file no 1 of 7\n",
      "done 8000of file no 1 of 7\n",
      "done 9000of file no 1 of 7\n",
      "done 10000of file no 1 of 7\n",
      "done 11000of file no 1 of 7\n",
      "done 12000of file no 1 of 7\n",
      "done 13000of file no 1 of 7\n",
      "done 14000of file no 1 of 7\n",
      "done 15000of file no 1 of 7\n",
      "done 0of file no 2 of 7\n",
      "done 1000of file no 2 of 7\n",
      "done 2000of file no 2 of 7\n",
      "done 3000of file no 2 of 7\n",
      "done 4000of file no 2 of 7\n",
      "done 5000of file no 2 of 7\n",
      "done 6000of file no 2 of 7\n",
      "done 7000of file no 2 of 7\n",
      "done 8000of file no 2 of 7\n",
      "done 9000of file no 2 of 7\n",
      "done 10000of file no 2 of 7\n",
      "done 0of file no 3 of 7\n",
      "done 1000of file no 3 of 7\n",
      "done 2000of file no 3 of 7\n",
      "done 3000of file no 3 of 7\n",
      "done 4000of file no 3 of 7\n",
      "done 5000of file no 3 of 7\n",
      "done 6000of file no 3 of 7\n",
      "done 7000of file no 3 of 7\n",
      "done 8000of file no 3 of 7\n",
      "done 9000of file no 3 of 7\n",
      "done 10000of file no 3 of 7\n",
      "done 11000of file no 3 of 7\n",
      "done 12000of file no 3 of 7\n",
      "done 13000of file no 3 of 7\n",
      "done 14000of file no 3 of 7\n",
      "done 15000of file no 3 of 7\n",
      "done 16000of file no 3 of 7\n",
      "done 0of file no 4 of 7\n",
      "done 1000of file no 4 of 7\n",
      "done 2000of file no 4 of 7\n",
      "done 3000of file no 4 of 7\n",
      "done 4000of file no 4 of 7\n",
      "done 5000of file no 4 of 7\n",
      "done 6000of file no 4 of 7\n",
      "done 7000of file no 4 of 7\n",
      "done 8000of file no 4 of 7\n",
      "done 9000of file no 4 of 7\n",
      "done 10000of file no 4 of 7\n",
      "done 0of file no 5 of 7\n",
      "done 1000of file no 5 of 7\n",
      "done 2000of file no 5 of 7\n",
      "done 3000of file no 5 of 7\n",
      "done 4000of file no 5 of 7\n",
      "done 5000of file no 5 of 7\n",
      "done 6000of file no 5 of 7\n",
      "done 7000of file no 5 of 7\n",
      "done 8000of file no 5 of 7\n",
      "done 9000of file no 5 of 7\n",
      "done 10000of file no 5 of 7\n",
      "done 11000of file no 5 of 7\n",
      "done 12000of file no 5 of 7\n",
      "done 13000of file no 5 of 7\n",
      "done 14000of file no 5 of 7\n",
      "done 15000of file no 5 of 7\n",
      "done 0of file no 6 of 7\n",
      "done 1000of file no 6 of 7\n",
      "done 2000of file no 6 of 7\n",
      "done 3000of file no 6 of 7\n",
      "done 4000of file no 6 of 7\n",
      "done 5000of file no 6 of 7\n",
      "done 6000of file no 6 of 7\n",
      "done 7000of file no 6 of 7\n",
      "done 8000of file no 6 of 7\n",
      "done 9000of file no 6 of 7\n",
      "done 10000of file no 6 of 7\n",
      "done 11000of file no 6 of 7\n",
      "done 12000of file no 6 of 7\n",
      "done 13000of file no 6 of 7\n",
      "done 14000of file no 6 of 7\n",
      "done 15000of file no 6 of 7\n",
      "done 16000of file no 6 of 7\n",
      "done 0of file no 7 of 7\n",
      "done 1000of file no 7 of 7\n",
      "done 2000of file no 7 of 7\n",
      "done 3000of file no 7 of 7\n",
      "done 4000of file no 7 of 7\n",
      "done 5000of file no 7 of 7\n",
      "done 6000of file no 7 of 7\n",
      "done 7000of file no 7 of 7\n",
      "done 8000of file no 7 of 7\n",
      "done 9000of file no 7 of 7\n",
      "done 10000of file no 7 of 7\n",
      "done 11000of file no 7 of 7\n",
      "done 12000of file no 7 of 7\n",
      "done 13000of file no 7 of 7\n",
      "done 14000of file no 7 of 7\n",
      "done 15000of file no 7 of 7\n",
      "done 16000of file no 7 of 7\n",
      "done 17000of file no 7 of 7\n"
     ]
    }
   ],
   "source": [
    "cellBarcodes = set(obsNames)\n",
    "rows = len(cellBarcodes)\n",
    "cols = adataList[0].shape[1]\n",
    "cellDict = dict(zip(cellBarcodes,range(rows)))\n",
    "X = np.zeros((rows,cols))\n",
    "S = np.zeros((rows,cols))\n",
    "U = np.zeros((rows,cols))\n",
    "XList = []\n",
    "SList = []\n",
    "UList = []\n",
    "obs = []\n",
    "var = []\n",
    "print('convering to array')\n",
    "for an in adataList:\n",
    "    XList.append(an.X.toarray())\n",
    "    SList.append(an.layers['spliced'].toarray())\n",
    "    UList.append(an.layers['unspliced'].toarray())\n",
    "    obs.append(an.obs)\n",
    "    var.append(an.var)\n",
    "print('adding values')\n",
    "for i in range(len(adataList)):\n",
    "    for j in range(adataList[i].shape[0]):\n",
    "        if j % 1000 == 0:\n",
    "            print('done ' + str(j) + 'of file no ' + str(i+1) + ' of ' + str(len(adataList)))\n",
    "        idx = cellDict[adataList[i].obs.index[j]]\n",
    "        X[idx] = X[idx] + XList[i][j]\n",
    "        S[idx] = S[idx] + SList[i][j]\n",
    "        U[idx] = U[idx] + UList[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('S', 11259388656),\n",
       " ('U', 11259388656),\n",
       " ('X', 11259388656),\n",
       " ('an', 9039661),\n",
       " ('cellBarcodes', 2097376),\n",
       " ('cellDict', 1310816),\n",
       " ('obsNames', 926760),\n",
       " ('var_names', 545712),\n",
       " ('adataNames', 768),\n",
       " ('samples', 768),\n",
       " ('sampleDict', 648),\n",
       " ('indices', 136),\n",
       " ('SList', 128),\n",
       " ('UList', 128),\n",
       " ('XList', 128),\n",
       " ('adataList', 128),\n",
       " ('checkSameVar', 128),\n",
       " ('obs', 128),\n",
       " ('var', 128),\n",
       " ('ad', 80),\n",
       " ('np', 80),\n",
       " ('sc', 80),\n",
       " ('scp', 80),\n",
       " ('s', 52),\n",
       " ('match', 51),\n",
       " ('check', 28),\n",
       " ('cols', 28),\n",
       " ('i', 28),\n",
       " ('idx', 28),\n",
       " ('j', 28),\n",
       " ('rows', 28)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(Fertig) Python 3.7",
   "language": "python",
   "name": "fertig_python_3_7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
